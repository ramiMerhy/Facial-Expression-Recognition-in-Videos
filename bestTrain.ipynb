{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training at  0\n",
      "length of train loader 421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmerhy\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [  0][  0/421]\tTrain Loss 1.9637\tTrain Accuaracy 19.444\t\n",
      "Epoch: [  0][  1/421]\tTrain Loss 1.9656\tTrain Accuaracy 18.056\t\n",
      "Epoch: [  0][  2/421]\tTrain Loss 1.9879\tTrain Accuaracy 15.741\t\n",
      "Epoch: [  0][  3/421]\tTrain Loss 1.9776\tTrain Accuaracy 13.889\t\n",
      "Epoch: [  0][  4/421]\tTrain Loss 1.9748\tTrain Accuaracy 14.444\t\n",
      "Epoch: [  0][  5/421]\tTrain Loss 1.9847\tTrain Accuaracy 12.963\t\n",
      "Epoch: [  0][  6/421]\tTrain Loss 1.9824\tTrain Accuaracy 13.492\t\n",
      "Epoch: [  0][  7/421]\tTrain Loss 1.9788\tTrain Accuaracy 13.194\t\n",
      "Epoch: [  0][  8/421]\tTrain Loss 1.9814\tTrain Accuaracy 12.346\t\n",
      "Epoch: [  0][  9/421]\tTrain Loss 1.9832\tTrain Accuaracy 12.500\t\n",
      "Epoch: [  0][ 10/421]\tTrain Loss 1.9871\tTrain Accuaracy 11.869\t\n",
      "Epoch: [  0][ 11/421]\tTrain Loss 1.9899\tTrain Accuaracy 11.574\t\n",
      "Epoch: [  0][ 12/421]\tTrain Loss 1.9886\tTrain Accuaracy 11.111\t\n",
      "Epoch: [  0][ 13/421]\tTrain Loss 1.9900\tTrain Accuaracy 11.111\t\n",
      "Epoch: [  0][ 14/421]\tTrain Loss 1.9884\tTrain Accuaracy 11.111\t\n",
      "Epoch: [  0][ 15/421]\tTrain Loss 1.9882\tTrain Accuaracy 11.111\t\n",
      "Epoch: [  0][ 16/421]\tTrain Loss 1.9848\tTrain Accuaracy 11.928\t\n",
      "Epoch: [  0][ 17/421]\tTrain Loss 1.9837\tTrain Accuaracy 11.883\t\n",
      "Epoch: [  0][ 18/421]\tTrain Loss 1.9827\tTrain Accuaracy 11.696\t\n",
      "Epoch: [  0][ 19/421]\tTrain Loss 1.9827\tTrain Accuaracy 11.528\t\n",
      "Epoch: [  0][ 20/421]\tTrain Loss 1.9824\tTrain Accuaracy 11.376\t\n",
      "Epoch: [  0][ 21/421]\tTrain Loss 1.9820\tTrain Accuaracy 11.869\t\n",
      "Epoch: [  0][ 22/421]\tTrain Loss 1.9795\tTrain Accuaracy 12.198\t\n",
      "Epoch: [  0][ 23/421]\tTrain Loss 1.9768\tTrain Accuaracy 12.269\t\n",
      "Epoch: [  0][ 24/421]\tTrain Loss 1.9763\tTrain Accuaracy 12.333\t\n",
      "Epoch: [  0][ 25/421]\tTrain Loss 1.9761\tTrain Accuaracy 12.393\t\n",
      "Epoch: [  0][ 26/421]\tTrain Loss 1.9753\tTrain Accuaracy 12.449\t\n",
      "Epoch: [  0][ 27/421]\tTrain Loss 1.9765\tTrain Accuaracy 12.302\t\n",
      "Epoch: [  0][ 28/421]\tTrain Loss 1.9769\tTrain Accuaracy 12.261\t\n",
      "Epoch: [  0][ 29/421]\tTrain Loss 1.9774\tTrain Accuaracy 12.315\t\n",
      "Epoch: [  0][ 30/421]\tTrain Loss 1.9768\tTrain Accuaracy 12.186\t\n",
      "Epoch: [  0][ 31/421]\tTrain Loss 1.9771\tTrain Accuaracy 12.066\t\n",
      "Epoch: [  0][ 32/421]\tTrain Loss 1.9770\tTrain Accuaracy 12.205\t\n",
      "Epoch: [  0][ 33/421]\tTrain Loss 1.9771\tTrain Accuaracy 12.173\t\n",
      "Epoch: [  0][ 34/421]\tTrain Loss 1.9773\tTrain Accuaracy 12.222\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-88db66ea7ce5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"length of train loader\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;31m#call the training function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m     \u001b[0mloss_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_accuaracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"length of validaiton loader\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-88db66ea7ce5>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, optimizer, loss_fn, epoch)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m#Backpropagation process (changing the weights)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(0)\n",
    "import argparse\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.models as models\n",
    "import load\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#check if we have a gpu to use it\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#batch of images for training\n",
    "batchsize_train=36\n",
    "#batch of images for evaluation\n",
    "batchsize_eval=1\n",
    "#number of frame taken from each video per input\n",
    "numberOfFrames=3\n",
    "#learing rate (change the step size and it can be specified by a trial error process)\n",
    "lr=0.00006\n",
    "#nb of times that we repeat our training on the data set\n",
    "epochs=200\n",
    "\n",
    "#check how many time the loss doesn't change and then stop training\n",
    "stoppingCriteria=10\n",
    "#convert the emotion strings to nb\n",
    "cat2Label={ \"Happy\": 0,\"Angry\": 1,  \"Disgust\": 2, \"Fear\": 3,\"Sad\": 4,\"Neutral\": 5,\"Surprise\": 6}\n",
    "\n",
    "#get the image and apply the data augmentation process by resizing it to 224*224; fix the image variations radomly (rotate the image, fix the zooming, translate its location and add black and white)\n",
    "transformTrain=transforms.Compose([transforms.Resize((224,224)), transforms.RandomHorizontalFlip(),transforms.RandomAffine(10, translate=[0.1,0.1], scale=[0.9, 1.25], shear=0.01), transforms.ToTensor()])\n",
    "#get the image and apply the data augmentation process by resizing it to 224*224; tensor: array in pytoch\n",
    "transformValidation=transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "\n",
    "root_train = './data/face/train_afew'\n",
    "list_train = './data/txt/afew_All.txt'\n",
    "\n",
    "root_eval = './data/face/val_afew'\n",
    "list_eval= './data/txt/afew_eval.txt'\n",
    "# load the data set\n",
    "train_loader, val_loader = load.frames3average(root_train, list_train, batchsize_train, root_eval, list_eval, batchsize_eval,numberOfFrames,cat2Label, transformTrain,transformValidation)\n",
    "\n",
    "#the train function get the images, the structure that we want to optimize, the optimizer, the loss function and the epoch\n",
    "def train(train_loader, model, optimizer,loss_fn, epoch):\n",
    "    #average meter: the sum values to create the elements\n",
    "    losses = load.AverageMeter()\n",
    "    accuaracy = load.AverageMeter()\n",
    "    #tell my model that we are training so the weights will change\n",
    "    model.train()\n",
    "    #input_var: the entered arrage; target_var: the label(emotion); path:path of the video; index:specify the index to create a map of the videos\n",
    "    for i, (input_var, target_var,path,index) in enumerate(train_loader):\n",
    "        \n",
    "        target_var = target_var.float().to(DEVICE)\n",
    "        #convert the input_vat from a python list to a pytorch tensor\n",
    "        input_var=torch.stack(input_var,4)\n",
    "\n",
    "        input_var = input_var.to(DEVICE)\n",
    "\n",
    "        #Feed forward command (go from the input to the label)\n",
    "        pred_score = model(input_var)\n",
    "        \n",
    "        #loss and accuaracy computation\n",
    "        loss = loss_fn(pred_score, target_var.long()).sum()\n",
    "        acc_iter = discreteAccuracy(pred_score.data, target_var)\n",
    "        #update the values after every training\n",
    "        losses.update(loss.item(), input_var.size(0))\n",
    "        accuaracy.update(acc_iter, input_var.size(0))\n",
    "    \n",
    "    \t#Backpropagation process (changing the weights)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        print('Epoch: [{:3d}][{:3d}/{:3d}]\\t'\n",
    "                  'Train Loss {loss.avg:.4f}\\t'\n",
    "                  'Train Accuaracy {accuaracy.avg:.3f}\\t'\n",
    "                .format(\n",
    "                epoch, i, len(train_loader), loss=losses, accuaracy=accuaracy))\n",
    "    \n",
    "    return losses.avg,accuaracy.avg\n",
    "\n",
    "\n",
    "def discreteAccuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(maxk, 1, True, True)  # first position is score; second position is pred.\n",
    "    pred = pred.t()  # .t() is T of matrix (256 * 1) -> (1 * 256)\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))  # target.view(1,2,2,-1): (256,) -> (1, 2, 2, 64)\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "\n",
    "    return res[0]\n",
    "\n",
    "\n",
    "def val(val_loader, model,loss_fn,classes):\n",
    "    \n",
    "    lossesVal = load.AverageMeter()\n",
    "    accuaracyVal = load.AverageMeter()\n",
    "\n",
    "    #tell the code that we don't need to change the weight\n",
    "    model.eval()\n",
    "    #tell the code to not compute the gradiant\n",
    "    with torch.no_grad():\n",
    "        for i, (input_var, target_var,path,index) in enumerate(val_loader):          \n",
    "            target_var = target_var.float().to(DEVICE)\n",
    "        \n",
    "            input_var=torch.stack(input_var,4)\n",
    "           \n",
    "            input_var = input_var.to(DEVICE)\n",
    "            pred_score = model(input_var)\n",
    "\n",
    "            loss = loss_fn(pred_score, target_var.long()).sum()\n",
    "            acc_iter = discreteAccuracy(pred_score.data, target_var)\n",
    "            \n",
    "            lossesVal.update(loss.item(), input_var.size(0))\n",
    "            accuaracyVal.update(acc_iter, input_var.size(0))\n",
    "\n",
    "            if i == (len(val_loader)-1):\n",
    "                print('Loss Validation  {loss.avg:.4f}\\t'\n",
    "                      'Validation accuaracy {accuaracy.avg:.3f}\\t'\n",
    "                    .format(loss=lossesVal, accuaracy=accuaracyVal))\n",
    "    \n",
    "\n",
    "    return accuaracyVal.avg,lossesVal.avg\n",
    "\n",
    "#define my loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "predictionsForPlot=[]\n",
    "\n",
    "#Network definition; convolution process\n",
    "#in_planes: input size; out_planes: output size; kernel_size: the mid layer (constructed by the W); stride: nb of skipped pixels; padding: how to treat the missing pixels; bias: constant values that we add or not\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "#define a block\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "#block: convolution then batch normalization then relu\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    #residual block equation\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "#define the structure\n",
    "class ResNet_AT(nn.Module):\n",
    "    def __init__(self, block, layers,featureVectoreSize):\n",
    "        super(ResNet_AT, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        #convolution then batch normalization then relu without creating a block\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        #max pooling: set the kernel and get the max value\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        #defining the layers (64,128,256 are the output size)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, featureVectoreSize, layers[3], stride=2)\n",
    "        #get the average pooling\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier=nn.Linear(512,7)\n",
    "        #initials weights based on a normal distribution\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    #creating layers and each layer has some blocks then make sure that input and output size of consecutive blocks are equal\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        #change dimention order\n",
    "        x=x.permute(0,4,1,2,3)\n",
    "        #check each dimension size\n",
    "        batch_size, seqlen, nc, h, w = x.size()\n",
    "        #combine the batch size and sequence lenght together\n",
    "        x = x.reshape(-1, nc, h, w)\n",
    "\n",
    "        #apply all the above to get the result (emotion)\n",
    "        f = self.conv1(x)\n",
    "        f = self.bn1(f)\n",
    "        f = self.relu(f)\n",
    "        f = self.maxpool(f)\n",
    "        f = self.layer1(f)\n",
    "        f = self.layer2(f)\n",
    "        f = self.layer3(f)\n",
    "        f = self.layer4(f)\n",
    "        f = self.avgpool(f)\n",
    "\n",
    "        #reduce the 30 values to 10 (each value has 3 emotion scores)\n",
    "        out = f.reshape(batch_size, seqlen, -1)\n",
    "        #average the result on the 3 images from the same video\n",
    "        out=out.mean(1)\n",
    "        #\n",
    "        out=self.classifier(out)\n",
    "        return out\n",
    "\n",
    "#allow to load the weights of the model\n",
    "def model_parameters(_structure, _parameterDir):\n",
    "    #checkpoint: a python dictionary where the weights are saved\n",
    "    checkpoint = torch.load(_parameterDir,map_location=torch.device('cpu'))\n",
    "    #state_dict: are the weights\n",
    "    pretrained_state_dict = checkpoint['state_dict']\n",
    "    model_state_dict = _structure.state_dict()\n",
    "\n",
    "    for key in pretrained_state_dict:\n",
    "        if ((key == 'module.fc.weight') | (key == 'module.fc.bias')):\n",
    "            pass\n",
    "        else:\n",
    "            model_state_dict[key.replace('module.', '')] = pretrained_state_dict[key]\n",
    "\n",
    "    #loading the weights\n",
    "    _structure.load_state_dict(model_state_dict)\n",
    "    #load them on the gpu if exists\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda available\")\n",
    "        model = torch.nn.DataParallel(_structure).cuda()\n",
    "    else:\n",
    "        model = torch.nn.DataParallel(_structure)\n",
    "\n",
    "    return model\n",
    "\n",
    "#define which basic block we need to use; the nb of blocks per layer; nb of layers; output size(stucture)\n",
    "def resnet18_at(featureVectoreSize, **kwargs):\n",
    "    # Constructs base a ResNet-18 model.\n",
    "    model = ResNet_AT(BasicBlock, [2, 2, 2, 2],featureVectoreSize, **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "#initialize model\n",
    "_structure=resnet18_at(512)\n",
    "_parameterDir = \"./pretrain_model/Resnet18_FER+_pytorch.pth.tar\"\n",
    "#load pretrained weight from google\n",
    "model = model_parameters(_structure, _parameterDir)\n",
    "model.classifier=nn.Sequential(nn.Linear(512,7))\n",
    "   \n",
    "\n",
    "#inititalize optimmizer\n",
    "optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr, momentum=0.9, weight_decay=1e-4)\n",
    "#reduce to 0.2 after 1000 step\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.2)\n",
    "      \n",
    "best_prec1=0\n",
    "\n",
    "predicitionsval=[]\n",
    "predictionstrain=[]\n",
    "lossestrain=[]\n",
    "lossesval=[]\n",
    "\n",
    "#how many times we need to repeat the training\n",
    "for epoch in range(epochs):\n",
    "    print(\"training at \", epoch)\n",
    "    ######Traind and validating###########################\n",
    "\n",
    "    print(\"length of train loader\",len(train_loader))\n",
    "    #call the training function\n",
    "    loss_train,train_accuaracy=train(train_loader, model, optimizer,loss_fn, epoch)\n",
    "\n",
    "    print(\"length of validaiton loader\",len(val_loader))\n",
    "    #call the validation function\n",
    "    validationAccuaracy,lossValidation = val(val_loader, model,loss_fn,cat2Label)\n",
    "    lossestrain.append(loss_train)\n",
    "    lossesval.append(lossValidation)\n",
    "    predictionstrain.append(train_accuaracy)\n",
    "    predicitionsval.append(validationAccuaracy)\n",
    "\n",
    "    ######Savind Best Model###############################\n",
    "    is_best = validationAccuaracy > best_prec1\n",
    "    if is_best:\n",
    "        worseCount=0\n",
    "        print('better model!\\n\\n')\n",
    "        pathModelSave=\"networksave/\"+\"net_\"+str(best_prec1)\n",
    "        torch.save(model.state_dict(), pathModelSave)\n",
    "    else:\n",
    "        print(\"model didnt improve \\n\\n\")\n",
    "        worseCount+=1\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    if(worseCount==stoppingCriteria):\n",
    "       print(\"training done\\n\\n\\n\")\n",
    "       break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
